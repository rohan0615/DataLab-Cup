{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the classes ordered by index\n",
    "classes = [\n",
    "    '__background__',  # always index 0\n",
    "    'aeroplane',\n",
    "    'bicycle',\n",
    "    'bird',\n",
    "    'boat',\n",
    "    'bottle',\n",
    "    'bus',\n",
    "    'car',\n",
    "    'cat',\n",
    "    'chair',\n",
    "    'cow',\n",
    "    'diningtable',\n",
    "    'dog',\n",
    "    'horse',\n",
    "    'motorbike',\n",
    "    'person',\n",
    "    'pottedplant',\n",
    "    'sheep',\n",
    "    'sofa',\n",
    "    'train',\n",
    "    'tvmonitor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_pickle('./dataset/train_data.pkl')\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare training data by transforming coordinates \n",
    "# [x1, y1, x2, y2] into [delta_x, delta_y, log(delta_w), log(delta_h)]\n",
    "def bbox_transform(ex_rois, gt_rois):\n",
    "\n",
    "    ex_widths = ex_rois[2] - ex_rois[0] + 1.0\n",
    "    ex_heights = ex_rois[3] - ex_rois[1] + 1.0\n",
    "    ex_ctr_x = ex_rois[0] + 0.5 * ex_widths\n",
    "    ex_ctr_y = ex_rois[1] + 0.5 * ex_heights\n",
    "\n",
    "    gt_widths = gt_rois[2] - gt_rois[0] + 1.0\n",
    "    gt_heights = gt_rois[3] - gt_rois[1] + 1.0\n",
    "    gt_ctr_x = gt_rois[0] + 0.5 * gt_widths\n",
    "    gt_ctr_y = gt_rois[1] + 0.5 * gt_heights\n",
    "\n",
    "    targets_dx = (gt_ctr_x - ex_ctr_x) / ex_widths\n",
    "    targets_dy = (gt_ctr_y - ex_ctr_y) / ex_heights\n",
    "    targets_dw = np.log(gt_widths / ex_widths)\n",
    "    targets_dh = np.log(gt_heights / ex_heights)\n",
    "\n",
    "    targets = np.array([targets_dx, targets_dy, targets_dw, targets_dh])\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Here we also resize the images into fixed 500*300 since the size of images are not the same\n",
    "width = 500\n",
    "height = 300\n",
    "boxes_resize = df_['boxes'].copy()\n",
    "for img in range(len(boxes_resize)):\n",
    "    imgage = Image.open(\"./dataset/JPEGImages/\" + df_['image_name'][img])\n",
    "    w = imgage.size[0]\n",
    "    h = imgage.size[1]\n",
    "    boxes = boxes_resize[img]\n",
    "\n",
    "    boxes[:, [0, 2]] = boxes[:, [0, 2]] * (width / w)\n",
    "    boxes[:, [1, 3]] = boxes[:, [1, 3]] * (height / h)\n",
    "    boxes_resize[img] = np.array([df_['gt_classes'][img][0]] + bbox_transform(\n",
    "      np.array([0, 0, width - 1, height - 1]), boxes[0]).tolist())\n",
    "\n",
    "df_['one_gt'] = boxes_resize\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = [300 for i in range(21)]\n",
    "df_select = df_.copy()\n",
    "for img in range(len(df_select)):\n",
    "    if class_count[int(df_select['one_gt'][img][0])] > 0:\n",
    "        class_count[int(df_select['one_gt'][img][0])] -= 1\n",
    "    else:\n",
    "        df_select = df_select.drop(img)\n",
    "\n",
    "df_select.reset_index(drop=True)\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_.to_pickle('./dataset/data_train_one.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 16\n",
    "img_width = 500\n",
    "img_height = 300\n",
    "num_classes = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.contrib.data import Dataset, Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_valid_split(df, valid_ratio):\n",
    "    valid_random = np.random.rand(len(df)) < valid_ratio\n",
    "    return df[~valid_random].reset_index(drop=True), df[valid_random].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./dataset/data_train_one.pkl')\n",
    "valid_ratio = 0.1\n",
    "df_train, df_valid = _train_valid_split(df, valid_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(image_name):\n",
    "    # For each image, generate an image array and its name. \n",
    "    # As a generator for tf.contrib.data.dataset to use.\n",
    "    file_path = './dataset/JPEGImages/'\n",
    "    img_file = tf.read_file(file_path + image_name)\n",
    "\n",
    "    img = tf.image.decode_image(img_file, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize_images(img, size=[img_width, img_height])\n",
    "\n",
    "    return img, image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensorflow iterator to process data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_image_name = tf.constant(df_train['image_name'].as_matrix())\n",
    "X_valid_image_name = tf.constant(df_valid['image_name'].as_matrix())\n",
    "\n",
    "train_dataset = Dataset.from_tensor_slices((X_train_image_name))\n",
    "valid_dataset = Dataset.from_tensor_slices((X_valid_image_name))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    data_generator, num_threads=4, output_buffer_size=8 * batch_size)\n",
    "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    data_generator, num_threads=4, output_buffer_size=8 * batch_size)\n",
    "valid_dataset = valid_dataset.shuffle(8 * batch_size)\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "#create TensorFlow Iterator object\n",
    "iterator = Iterator.from_structure(train_dataset.output_types,\n",
    "                                   train_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "#create two initialization ops to switch between the datasets\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "validation_init_op = iterator.make_initializer(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define single layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolution\n",
    "def conv2d(name, input_layer, kernel_size, filters, padding='same', relu=True):\n",
    "    if relu:\n",
    "        output = tf.layers.conv2d(\n",
    "            inputs=input_layer,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            activation=tf.nn.relu,\n",
    "            name=name)\n",
    "    else:\n",
    "        output = tf.layers.conv2d(\n",
    "            inputs=input_layer,\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            name=name)\n",
    "    return output\n",
    "\n",
    "\n",
    "# max pooling\n",
    "def max_pool(name, input_layer, window):\n",
    "    return tf.layers.max_pooling2d(\n",
    "        inputs=input_layer, pool_size=[window, window], strides=window)\n",
    "\n",
    "\n",
    "def norm(name, input_layer):\n",
    "    return tf.layers.batch_normalization(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNModel(object):\n",
    "\n",
    "    def __init__(self, name='cnn'):\n",
    "        self.name = name\n",
    "        self.istrain = True\n",
    "        with tf.variable_scope(self.name) as scope:\n",
    "            try:\n",
    "                self.build_model()\n",
    "            except ValueError:\n",
    "                scope.reuse_variables()\n",
    "                self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        #input image and roiboxes\n",
    "        self.input_layer = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, img_width, img_height, 3])\n",
    "        #input traning ground truth [batch_numer, [label, 4]]\n",
    "        self.gt_bbox_targets = tf.placeholder(dtype=tf.float32, shape=[None, 5])\n",
    "\n",
    "        #conv 1\n",
    "        conv1_1 = conv2d('conv1_1', self.input_layer, [3, 3], 64)\n",
    "        pool1 = max_pool('pool1', conv1_1, 2)\n",
    "        norm1 = norm('norm1', pool1)\n",
    "\n",
    "        conv1_2 = conv2d('conv1_2', norm1, [3, 3], 64)\n",
    "        pool2 = max_pool('pool2', conv1_2, 2)\n",
    "        norm2 = norm('norm2', pool2)\n",
    "\n",
    "        conv2_1 = conv2d('conv2_1', norm2, [3, 3], 64)\n",
    "        pool2_2 = max_pool('pool2_2', conv2_1, 2)\n",
    "        norm2_2 = norm('norm2_2', pool2_2)\n",
    "\n",
    "        conv3_1 = conv2d('conv3_1', norm2_2, [3, 3], 64)\n",
    "        pool3_1 = max_pool('pool3_1', conv3_1, 2)\n",
    "        norm3_1 = norm('norm3_1', pool3_1)\n",
    "\n",
    "        conv3_2 = conv2d('conv3_2', norm3_1, [3, 3], 64)\n",
    "        pool3_2 = max_pool('pool3_2', conv3_2, 4)\n",
    "        norm3_2 = norm('norm3_2', pool3_2)\n",
    "\n",
    "        flatten = tf.reshape(norm3_2, [-1, 1792])\n",
    "\n",
    "        #dense layers\n",
    "        dense1 = tf.layers.dense(flatten, 128, activation=tf.nn.relu)\n",
    "        dropout1 = tf.layers.dropout(dense1, rate=0.4, training=self.istrain)\n",
    "\n",
    "        dense2 = tf.layers.dense(dropout1, 256, activation=tf.nn.relu)\n",
    "        dropout2 = tf.layers.dropout(dense2, rate=0.4, training=self.istrain)\n",
    "\n",
    "        #box and class predication\n",
    "        ##for object classification\n",
    "        self.logits_cls = tf.layers.dense(dropout2, num_classes)\n",
    "        self.out_cls = tf.nn.softmax(self.logits_cls)\n",
    "\n",
    "        ##for bounding box prediction\n",
    "        self.logits_reg = tf.layers.dense(dropout2, 4)\n",
    "\n",
    "        #calculate loss\n",
    "        gt_cls, gt_reg = tf.split(self.gt_bbox_targets, [1, 4], 1)\n",
    "\n",
    "        gt_cls_raw = tf.cast(gt_cls, tf.int64)\n",
    "        gt_cls = tf.reshape(tf.one_hot(gt_cls_raw, num_classes), [-1, num_classes])\n",
    "\n",
    "        self.loss_cls = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                labels=gt_cls, logits=self.logits_cls))\n",
    "\n",
    "        self.loss_reg = tf.losses.mean_squared_error(gt_reg, self.logits_reg)\n",
    "\n",
    "        self.loss = self.loss_cls + 2 * self.loss_reg\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, [])\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "\n",
    "    def save_model(self, sess, global_step):\n",
    "        var_list = [v for v in tf.global_variables() if self.name in v.name]\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        saver.save(sess, './checkpoint/cnn', global_step)\n",
    "\n",
    "    def load_model(self, sess):\n",
    "        var_list = [v for v in tf.global_variables() if self.name in v.name]\n",
    "        saver = tf.train.Saver(var_list)\n",
    "        ckpt = tf.train.get_checkpoint_state('./checkpoint/')\n",
    "        tf.logging.info('Loading model %s.', ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    def test_mode(self):\n",
    "        self.istrain = False\n",
    "\n",
    "    def train_mode(self):\n",
    "        self.istrain = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for each image, get the ground truth target to feed when training\n",
    "def get_ground_truth(x_indx, dataframe):\n",
    "    target_batch = []\n",
    "    for indx in x_indx:\n",
    "        target_batch.append(dataframe['one_gt'][indx])\n",
    "    return np.array(target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(sess, model, epoch=5):\n",
    "    for e in range(epoch):\n",
    "        model.train_mode()\n",
    "        sess.run(training_init_op)\n",
    "        losses = []\n",
    "        count = 0\n",
    "        while True:\n",
    "            try:\n",
    "                x_img, x_img_names = sess.run(next_element)\n",
    "                x_indx = [\n",
    "                    df_train.index[df_train['image_name'] == name.decode(\"utf-8\")]\n",
    "                    .tolist()[0] for name in x_img_names\n",
    "                ]\n",
    "\n",
    "                y_gt = get_ground_truth(x_indx, df_train)\n",
    "                feed_dict = {\n",
    "                    model.input_layer: x_img,\n",
    "                    model.gt_bbox_targets: y_gt,\n",
    "                    model.lr: 0.0001,\n",
    "                }\n",
    "\n",
    "                _, loss, step = sess.run(\n",
    "                    [model.train_op, model.loss, model.global_step],\n",
    "                    feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('%d epoch with training loss %f' % (e, np.mean(losses)))\n",
    "                break\n",
    "\n",
    "        model.test_mode()\n",
    "        sess.run(validation_init_op)\n",
    "        losses_v = []\n",
    "        while True:\n",
    "            try:\n",
    "                x_img, x_img_names = sess.run(next_element)\n",
    "                x_indx = [\n",
    "                    df_valid.index[df_valid['image_name'] == name.decode(\"utf-8\")]\n",
    "                    .tolist()[0] for name in x_img_names\n",
    "                ]\n",
    "                y_gt = get_ground_truth(x_indx, df_valid)\n",
    "\n",
    "                feed_dict = {\n",
    "                    model.input_layer: x_img,\n",
    "                    model.gt_bbox_targets: y_gt,\n",
    "                }\n",
    "\n",
    "                loss = sess.run([model.loss], feed_dict=feed_dict)\n",
    "\n",
    "                losses_v.append(loss)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print('%d epoch with validation loss %f\\n' % (e, np.mean(losses_v)))\n",
    "                break\n",
    "    return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "sess = tf.Session()\n",
    "with tf.device('/device:GPU:0'):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    step = train_model(sess, model)\n",
    "model.save_model(sess, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and run evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle('./dataset/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#read testing data\n",
    "X_test_image_name = tf.constant(df_test['image_name'].as_matrix())\n",
    "test_dataset = Dataset.from_tensor_slices((X_test_image_name))\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    data_generator, num_threads=4, output_buffer_size=20)\n",
    "test_dataset = test_dataset.batch(1)\n",
    "\n",
    "iterator = Iterator.from_structure(test_dataset.output_types,\n",
    "                                   test_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "testing_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = CNNModel()\n",
    "\n",
    "result_cls, result_reg = [], []\n",
    "with tf.Session() as sess:\n",
    "    model.load_model(sess)\n",
    "    model.test_mode()\n",
    "    with tf.device('/gpu:0'):\n",
    "        sess.run(testing_init_op)\n",
    "        while True:\n",
    "            try:\n",
    "                x_img, x_img_name = sess.run(next_element)\n",
    "\n",
    "                feed_dict = {model.input_layer: x_img}\n",
    "\n",
    "                logits_cls, logits_reg = sess.run(\n",
    "                    [model.out_cls, model.logits_reg], feed_dict=feed_dict)\n",
    "\n",
    "                result_cls.append(logits_cls)\n",
    "                result_reg.append(logits_reg)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function from regression output to bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_to_bbox(reg, box):\n",
    "    bbox_width = box[2] - box[0] + 1.0\n",
    "    bbox_height = box[3] - box[1] + 1.0\n",
    "    bbox_ctr_x = box[0] + 0.5 * bbox_width\n",
    "    bbox_ctr_y = box[1] + 0.5 * bbox_height\n",
    "\n",
    "    out_ctr_x = reg[0] * bbox_width + bbox_ctr_x\n",
    "    out_ctr_y = reg[1] * bbox_height + bbox_ctr_y\n",
    "\n",
    "    out_width = bbox_width * 10**reg[2]\n",
    "    out_height = bbox_height * 10**reg[3]\n",
    "\n",
    "    return np.array([\n",
    "        max(0, out_ctr_x - 0.5 * out_width),\n",
    "        max(0, out_ctr_y - 0.5 * out_height),\n",
    "        min(img_width, out_ctr_x + 0.5 * out_width),\n",
    "        min(img_height, out_ctr_y + 0.5 * out_height)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test_img = df_test.shape[0]\n",
    "\n",
    "bbox_preds = []\n",
    "bbox_cls = []\n",
    "for img in range(num_test_img):\n",
    "    bbox_pred = []\n",
    "    bbox_c = []\n",
    "    bbox_pred.append(\n",
    "      reg_to_bbox(result_reg[img][0], np.array([0, 0, img_width, img_height])))\n",
    "    bbox_c.append(np.argmax(result_cls[img]))\n",
    "\n",
    "    bbox_cls.append(np.array(bbox_c))\n",
    "    bbox_preds.append(np.array(bbox_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for img in range(num_test_img):\n",
    "    imgage = Image.open(\"./dataset/JPEGImages/\" + df_test['image_name'][img])\n",
    "    w = imgage.size[0]\n",
    "    h = imgage.size[1]\n",
    "    boxes = bbox_preds[img]\n",
    "\n",
    "    boxes[:, [0, 2]] = boxes[:, [0, 2]] * (w / img_width)\n",
    "    boxes[:, [1, 3]] = boxes[:, [1, 3]] * (h / img_height)\n",
    "    bbox_preds[img] = boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation function and get csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#please ad ./evaluate file into your system path\n",
    "sys.path.insert(0, './evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from evaluate import *\n",
    "evaluate(bbox_preds, bbox_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "show = 21\n",
    "im = np.array(\n",
    "    Image.open(\"./dataset/JPEGImages/\" + df_test['image_name'][show]),\n",
    "    dtype=np.uint8)\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "# Show the image\n",
    "ax.imshow(im)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "x1, y1, x2, y2 = bbox_preds[show][0].astype(int)\n",
    "\n",
    "rect = patches.Rectangle(\n",
    "    (x1, y1),\n",
    "    x2 - x1,\n",
    "    y2 - y1,\n",
    "    linewidth=2,\n",
    "    edgecolor='r',\n",
    "    facecolor='none',\n",
    "    label=classes[int(bbox_cls[show])])\n",
    "\n",
    "# Add the bounding box to the Axes\n",
    "ax.add_patch(rect)\n",
    "plt.text(x1, y1, classes[int(bbox_cls[show])], color='blue', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
